{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tharunkunamalla/Project-2-Labementix-PhonePe_Transaction_Insights/blob/main/phonepe_Transactions_Insights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    - phonepe Transactions Insights\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual/Team --> Individual\n",
        "##### **Team Member 1 -** Tharun Kunamalla\n",
        "##### **Team Member 2 -**\n",
        "##### **Team Member 3 -**\n",
        "##### **Team Member 4 -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "Write the summary here within 500-600 words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la_jwIVZSc-H"
      },
      "source": [
        "The PhonePe Transaction Insights project is a data analytics and visualization solution built to analyze digital transaction patterns across Indian states and districts using PhonePe’s publicly available dataset. The project uses ETL (Extract, Transform, Load) processes to extract data from a GitHub repository, store it in a SQL database, and analyze it using SQL and Python. Key insights are visualized using an interactive dashboard built with Streamlit, enabling real-time data exploration.\n",
        "\n",
        "The project organizes data into three core categories — Aggregated, Map, and Top — covering users, transactions, and insurance. SQL queries were crafted to address business use cases like customer segmentation, geographical analysis, user engagement, and fraud detection. These outputs were further visualized using Pandas, Matplotlib, and Seaborn, integrated into a Streamlit dashboard.\n",
        "\n",
        "Through this project, users gain hands-on experience in data engineering, analytical thinking, and dashboard development within the finance and payment systems domain. Additionally, this end-to-end pipeline illustrates how raw digital transaction data can be transformed into impactful business intelligence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "Provide your GitHub Link here: https://github.com/Tharunkunamalla/Project-2-Labementix-PhonePe_Transaction_Insights.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "**Write Problem Statement Here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNu3Z4rtR-_g"
      },
      "source": [
        "In today’s digital-first economy, platforms like PhonePe handle millions of transactions daily across diverse regions of India. However, to maintain a competitive edge and improve customer satisfaction, it is critical to derive actionable insights from this massive pool of data. The challenge lies in organizing, analyzing, and visualizing this information to understand user behavior, monitor transaction trends, and evaluate the performance of financial services like insurance. This project focuses on building a comprehensive data pipeline and visualization dashboard to extract meaningful insights from PhonePe’s transaction data, helping businesses and stakeholders make data-driven decisions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgbUHAGgjLW"
      },
      "source": [
        "# **General Guidelines** : -  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      },
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "agg_ins_df = pd.read_csv('/content/sample_data/aggregated_insurance.csv')\n",
        "agg_trans_df = pd.read_csv('/content/sample_data/aggregated_transaction.csv')\n",
        "agg_user_df = pd.read_csv('/content/sample_data/aggregated_user.csv')\n",
        "map_ins_df = pd.read_csv('/content/sample_data/map_insurance.csv')\n",
        "map_trans_df = pd.read_csv('/content/sample_data/map_transaction.csv')\n",
        "map_user_df = pd.read_csv('/content/sample_data/map_user.csv')\n",
        "top_ins_df = pd.read_csv('/content/sample_data/top_insurance.csv')\n",
        "top_trans_df = pd.read_csv('/content/sample_data/top_transaction.csv')\n",
        "top_user_df = pd.read_csv('/content/sample_data/top_user.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "print(\"Aggregated: \\n\")\n",
        "print(agg_ins_df.head())\n",
        "print(agg_trans_df.head())\n",
        "print(agg_user_df.head())\n",
        "print(\"Map: \\n\")\n",
        "print(map_ins_df.head())\n",
        "print(map_trans_df.head())\n",
        "print(map_user_df.head())\n",
        "print(\"Top : \\n\")\n",
        "print(top_ins_df.head())\n",
        "print(top_trans_df.head())\n",
        "print(top_user_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "# Print rows and columns count\n",
        "dfs = {\n",
        "    'Aggregated Insurance': agg_ins_df,\n",
        "    'Aggregated Transactions': agg_trans_df,\n",
        "    'Aggregated Users': agg_user_df,\n",
        "    'Map Insurance': map_ins_df,\n",
        "    'Map Transactions': map_trans_df,\n",
        "    'Map Users': map_user_df,\n",
        "    'Top Insurance': top_ins_df,\n",
        "    'Top Transactions': top_trans_df,\n",
        "}\n",
        "\n",
        "for name, df in dfs.items():\n",
        "    print(f\"{name}: {df.shape[0]} rows × {df.shape[1]} columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "# Gets the info of all files\n",
        "for name, df in dfs.items():\n",
        "    print(f\"\\n {name} Info:\")\n",
        "    display(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(\" Duplicate Rows:\", df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(\"Null Values:\\n\", df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "outputs": [],
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(), cbar=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cxe7DzLVXEz"
      },
      "source": [
        "### In the Above visualization we cant see the missing values because there are only 2 soo it cant be visualize..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccZdBg7NVZsf"
      },
      "source": [
        "but in the Null values we got that pincodes are missing so toget the data we seperately called"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rD1Cqx41Vexw"
      },
      "outputs": [],
      "source": [
        "missing_rows = df[df['Pincodes'].isnull()]\n",
        "print(missing_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "Answer Here: <br>\n",
        "1. Aggregated Datasets\n",
        "These datasets show overall statistics per state/district over time—not user-level data, but summary level (macro) data. The categories are usually:\n",
        "\n",
        "- a. aggregated/transaction\n",
        "Purpose: Show volume and value of transactions made on PhonePe.\n",
        "\n",
        "- Columns (after conversion):state, year, quarter\n",
        "transaction_type (e.g., recharge, peer-to-peer, merchant, etc.)\n",
        "transaction_count\n",
        "transaction_amount\n",
        "- b. aggregated/user\n",
        "Purpose: Number of users and app opens.\n",
        "- Columns:\n",
        "state, year, quarter\n",
        "device_brand\n",
        "user_count, percentage_share (optional depending on data version)\n",
        "- c. aggregated/insurance\n",
        "Purpose: Shows digital insurance bought through PhonePe.\n",
        "- Columns:\n",
        "state, year, quarter\n",
        "insurance_type (e.g., health, life)\n",
        "premium_amount, policy_count\n",
        "\n",
        "2. Map Datasets\n",
        "These datasets allow geographical-level analysis, usually at state/district level. They’re still aggregated but are location-mapped.\n",
        "\n",
        "- a. map/transaction\n",
        "Purpose: Geo-level data of PhonePe transactions.\n",
        "\n",
        "- Columns:\n",
        "state, district, year, quarter\n",
        "transaction_count, transaction_amount\n",
        "\n",
        "- b. map/user\n",
        "Purpose: Geo-level data of user registrations.\n",
        "\n",
        "- Columns:\n",
        "state, district, year, quarter\n",
        "registered_users, app_opens\n",
        "\n",
        "3. Top Datasets\n",
        "These show top 10 categories in certain metrics. Great for leaderboards or ranking analysis.\n",
        "\n",
        "- a. top/transaction\n",
        "Purpose: Top 10 states/districts with highest transaction count/value.\n",
        "\n",
        "- Columns:\n",
        "state, district, year, quarter\n",
        "transaction_type, transaction_count, transaction_amount\n",
        "\n",
        "- b. top/user\n",
        "Purpose: Top 10 states/districts by registered users and app opens.\n",
        "\n",
        "- Columns:\n",
        "state, district, year, quarter\n",
        "registered_users\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmdE6L8BVoAm"
      },
      "outputs": [],
      "source": [
        "agg_trans_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "Answer Here: in the Variables description we had found that mean, count, std, min, 25%, 50%, 75% max values from the describe method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Data Wrangling***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJF3rekwFvQ"
      },
      "source": [
        "### Data Wrangling Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "outputs": [],
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#step 1:\n",
        "#Cleanup the dataset\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(inplace=True) #This removes duplicates\n",
        "\n",
        "# Standardize column names (optional but cleaner)\n",
        "df.columns = df.columns.str.strip().str.replace(\" \", \"_\").str.lower()\n",
        "\n",
        "# Check for nulls\n",
        "print(\"Null Values:\\n\", df.isnull().sum())\n",
        "\n",
        "#Step2:\n",
        "#Handling missing values:\n",
        "# Check how many missing pincodes\n",
        "print(\"Missing Pincodes:\", df['pincodes'].isnull().sum())\n",
        "\n",
        "# Option 1: Fill with mode (most frequent pincode)\n",
        "df['pincodes'] = df['pincodes'].fillna(df['pincodes'].mode()[0]) # Replaces the NaN entries in pincodes with that most common value.(that is frequently occuring)\n",
        "# print(df.isnull().sum()) --> to check... but already the missing values got replaced\n",
        "\n",
        "# step3:\n",
        "# Ensure years and quarter are integer if not already\n",
        "df['years'] = df['years'].astype(int)\n",
        "df['quarter'] = df['quarter'].astype(int)\n",
        "\n",
        "# Convert pincode to string (categorical-like)\n",
        "df['pincodes'] = df['pincodes'].astype(str)\n",
        "\n",
        "#Step4:\n",
        "# Create a 'year_quarter' column\n",
        "df['year_quarter'] = df['years'].astype(str) + '-Q' + df['quarter'].astype(str)\n",
        "agg_trans_df['year_quarter'] = agg_trans_df['Years'].astype(str) + '-Q' + agg_trans_df['Quarter'].astype(str)\n",
        "agg_ins_df['year_quarter'] = agg_ins_df['Years'].astype(str) + '-Q' + agg_ins_df['Quarter'].astype(str)\n",
        "agg_user_df['year_quarter'] = agg_user_df['Years'].astype(str) + '-Q' + agg_user_df['Quarter'].astype(str)\n",
        "map_trans_df['year_quarter'] = map_trans_df['Years'].astype(str) + '-Q' + map_trans_df['Quarter'].astype(str)\n",
        "map_ins_df['year_quarter'] = map_ins_df['Years'].astype(str) + '-Q' + map_ins_df['Quarter'].astype(str)\n",
        "map_user_df['year_quarter'] = map_user_df['Years'].astype(str) + '-Q' + map_user_df['Quarter'].astype(str)\n",
        "top_trans_df['year_quarter'] = top_trans_df['years'].astype(str) + '-Q' + top_trans_df['quarter'].astype(str)\n",
        "top_ins_df['year_quarter'] = top_ins_df['Years'].astype(str) + '-Q' + top_ins_df['Quarter'].astype(str)\n",
        "top_user_df['year_quarter'] = top_user_df['Years'].astype(str) + '-Q' + top_user_df['Quarter'].astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQ2gWgMqWLhb"
      },
      "outputs": [],
      "source": [
        "map_user_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "Answer Here:\n",
        "In This i have made in steps wise:\n",
        "- step1: removed duplicated values\n",
        "- step2: gone through the dataset to check the missing values(NAN).\n",
        "  - Found the missing values in the pincodes so replaced with the most occuring values in the pincodes\n",
        "- step3: In this step we made the columns of years, quarter to int type only.... and pincodes as string type\n",
        "- step4: made a new column for year_quarter for better visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization code\n",
        "df1 = agg_trans_df.groupby(\"States\")[\"Transaction_amount\"].sum().sort_values(ascending=False)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=df1.index, y=df1.values, palette=\"viridis\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Total Transaction Amount by State\")\n",
        "plt.xlabel(\"States\")\n",
        "plt.ylabel(\"Transaction Amount\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "Answer Here: This bar chart clearly compares the transaction volume between states. Bar charts are excellent for state-wise aggregation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "Answer Here:\n",
        "- Insights:\n",
        "   - Telangana Maharashtra, Karnataka, and Tamil Nadu lead in transaction amount.\n",
        "\n",
        "  - Smaller UTs(union terristories) like Lakshadweep and Ladakh have very low volume."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448CDAPjqfQr"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "Answer Here:\n",
        "  * High-performing states can be used for launching new premium services\n",
        "  \n",
        "  - Underperforming regions can be targeted with promotional offers to boost adoption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Chart - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "ch2 = agg_trans_df.groupby(\"year_quarter\")[\"Transaction_amount\"].sum().reset_index()\n",
        "sns.lineplot(data=ch2, x=\"year_quarter\", y=\"Transaction_amount\", marker=\"o\", color=\"orange\")\n",
        "plt.title(\"Chart 2: Transaction Amount Over Time (Aggregated Transactions)\")\n",
        "plt.ylabel(\"Amount (INR)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dVpIINYklI"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": [
        "Answer Here: This line chart displays changes in monetary transaction volume over time, essential for understanding financial performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmpgYnKYklI"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "Answer Here: Transaction amount generally rises with transaction count, but the rate of growth can vary. A sudden jump may indicate B2B adoption or large-value partnerships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JiQyfWJYklI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        "Answer Here: <br>\n",
        "Positive: Indicates user trust and higher value usage.<br>\n",
        "Negative: If growth is slow despite rising user count, it may point to low-value transactions needing targeted merchant strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo"
      },
      "source": [
        "#### Chart - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "outputs": [],
      "source": [
        "# Chart - 3 visualization code\n",
        "ch_3 = agg_trans_df.groupby(\"Transaction_type\")[\"Transaction_count\"].sum().reset_index()\n",
        "sns.barplot(data=ch_3, x=\"Transaction_type\", y=\"Transaction_count\", palette=\"Set2\")\n",
        "plt.title(\"Chart 3: Transaction Type Distribution (Aggregated Transactions)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fge-S5ZAYoAp"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBItgRVYoAp"
      },
      "source": [
        "Answer Here: A bar chart clearly compares different transaction types like \"Recharge\", \"Peer-to-peer\", \"Merchant Payments\", etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85gYPyotYoAp"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jstXR6OYoAp"
      },
      "source": [
        "Answer Here: Some transaction types dominate usage (e.g., P2P transfers), while others like utility payments may lag behind."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoGjAbkUYoAp"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      },
      "source": [
        "Answer Here: Helps identify which services to promote or improve. Low-performing types can be targeted with new features or offers. High usage areas reinforce brand identity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM"
      },
      "source": [
        "#### Chart - 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "outputs": [],
      "source": [
        "# Chart - 4 visualization code\n",
        "ch_4 = agg_trans_df.groupby(\"States\")[\"Transaction_count\"].sum().sort_values(ascending=False).head(10).reset_index()\n",
        "sns.barplot(data=ch_4, x=\"Transaction_count\", y=\"States\", palette=\"magma\")\n",
        "plt.title(\"Chart 4: Top States by Transaction Count (Aggregated Transactions)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iky9q4vBYrdO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJRCwT6DYrdO"
      },
      "source": [
        "Answer Here: A horizontal bar chart highlights regional activity and penetration across India."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6T5p64dYrdO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      },
      "source": [
        "Answer Here: States like Maharashtra, Karnataka, and Telangana may show the highest volume."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Ehk30pYrdP"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNxxz7MYrdP"
      },
      "source": [
        "Answer Here: <br>\n",
        "Positive: Helps allocate marketing resources and support based on performance.<br>\n",
        "Negative: Underperforming states signal areas needing awareness campaigns or better onboarding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1"
      },
      "source": [
        "#### Chart - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "outputs": [],
      "source": [
        "# Chart - 5 visualization code\n",
        "chart5_data = agg_trans_df.groupby(\"States\")[\"Transaction_amount\"].sum().sort_values(ascending=False).head(10).reset_index()\n",
        "sns.barplot(data=chart5_data, x=\"Transaction_amount\", y=\"States\", palette=\"viridis\")\n",
        "plt.title(\"Chart 5: Top States by Transaction Amount (Aggregated Transactions)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcxuIMRPYuh3"
      },
      "source": [
        "Answer Here: It shows where the highest monetary transactions happen, which may differ from transaction count."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzvFGzlYuh3"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyqkiB8YYuh3"
      },
      "source": [
        "Answer Here: -States with industrial hubs or high-income populations show higher amounts, even if transaction count is moderate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpmQ266Yuh3"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      },
      "source": [
        "Answer Here: Helps identify premium customers. Tailored services (like insurance or investment) can be promoted in high-value states."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM"
      },
      "source": [
        "#### Chart - 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "# Chart - 6 visualization code\n",
        "ch_6 = map_user_df.groupby(\"year_quarter\")[\"RegisteredUser\"].sum().reset_index()\n",
        "sns.lineplot(data=ch_6, x=\"year_quarter\", y=\"RegisteredUser\", marker=\"o\", color=\"purple\")\n",
        "plt.title(\"Chart 6: Registered Users Over Time (Map Users)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFf2-_FphqN"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loh7H2nzphqN"
      },
      "source": [
        "Answer Here: User growth over time is best shown using a line chart, making it easy to see adoption trends."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouA3fa0phqN"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VECbqPI7phqN"
      },
      "source": [
        "Answer Here: Registered users increase steadily, validating user onboarding efforts. national initiatives (like UPI integration with banks)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seke61FWphqN"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW4_bGpfphqN"
      },
      "source": [
        "Answer Here: More users mean a larger customer base for monetization. If user growth slows, re-engagement or regional campaigns may be required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN"
      },
      "source": [
        "#### Chart - 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 7 visualization code\n",
        "insurance_data = agg_ins_df.groupby(\"year_quarter\")[[\"Insurance_count\", \"Insurance_amount\"]].sum().reset_index()\n",
        "sns.lineplot(data=insurance_data, x=\"year_quarter\", y=\"Insurance_count\", marker=\"o\", label=\"Count\")\n",
        "sns.lineplot(data=insurance_data, x=\"year_quarter\", y=\"Insurance_amount\", marker=\"o\", label=\"Amount\")\n",
        "plt.title(\"Chart 7: Insurance Count & Amount Over Time (Aggregated Insurance)\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t27r6nlMphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv6ro40sphqO"
      },
      "source": [
        "Answer Here: A dual-line chart helps compare two metrics (insurance count and amount) over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2jJGEOYphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po6ZPi4hphqO"
      },
      "source": [
        "Answer Here: Insurance services are gaining adoption, but amounts may remain low, indicating small-ticket policies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0JNsNcRphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSq8iUTphqO"
      },
      "source": [
        "Answer Here: Opportunity to scale financial services. Micro-insurance is growing. Larger policy types can be introduced based on user maturity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZR9WyysphqO"
      },
      "source": [
        "#### Chart - 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 8 visualization code\n",
        "district_insurance = map_ins_df.groupby(\"Districts\")[\"Transaction_count\"].sum().sort_values(ascending=False).head(10).reset_index()\n",
        "sns.barplot(data=district_insurance, x=\"Transaction_count\", y=\"Districts\", palette=\"coolwarm\")\n",
        "plt.title(\"Chart 8: Top Districts by Insurance Count (Map Insurance)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7wYXLtphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob8u6rCTphqO"
      },
      "source": [
        "Answer Here: District-level analysis pinpoints where insurance services are most used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZrbJ2SmphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZtgC_hjphqO"
      },
      "source": [
        "Answer Here: Urban districts dominate. Semi-urban areas show potential if infrastructure is improved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFu4xreNphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey_0qi68phqO"
      },
      "source": [
        "Answer Here: Supports location-based policy marketing. Underserved areas offer growth opportunities with the right education and support."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ55k-q6phqO"
      },
      "source": [
        "#### Chart - 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 9 visualization code\n",
        "top_pin_txn = top_trans_df.groupby(\"pincodes\")[\"transaction_count\"].sum().sort_values(ascending=False).head(10).reset_index()\n",
        "sns.barplot(data=top_pin_txn, x=\"transaction_count\", y=\"pincodes\", palette=\"flare\")\n",
        "plt.title(\"Chart 9: Top pincodes by Transaction Count (Top Transactions)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCFgpxoyphqP"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVxDimi2phqP"
      },
      "source": [
        "Answer Here: Pincodes reflect micro-locations. A bar chart shows hyperlocal performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVtJsKN_phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngGi97qjphqQ"
      },
      "source": [
        "Answer Here: Pincodes in metropolitan areas lead, but surprising growth in Tier-3 towns indicates nice development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lssrdh5qphqQ"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBpY5ekJphqQ"
      },
      "source": [
        "Answer Here: Can guide local ads, UPI QR deployments, and merchant onboarding in high-usage areas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      },
      "source": [
        "#### Chart - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "outputs": [],
      "source": [
        "# Chart - 10 visualization code\n",
        "brand_trend = agg_user_df.groupby([\"year_quarter\", \"Brands\"])[\"Transaction_count\"].sum().reset_index()\n",
        "sns.lineplot(data=brand_trend, x=\"year_quarter\", y=\"Transaction_count\", hue=\"Brands\")\n",
        "plt.title(\"Chart 10: Brand-wise Transactions Over Time (Aggregated Users)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M8mcRywphqQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8agQvks0phqQ"
      },
      "source": [
        "Answer Here: Line plots with color-coded brands show device-based engagement trends."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgIPom80phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp13pnNzphqQ"
      },
      "source": [
        "Answer Here: Brands like Xiaomi and Samsung may dominate due to affordability and market share. Some brands show rapid growth quarter by quarter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMzcOPDDphqR"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Ka1PC2phqR"
      },
      "source": [
        "Answer Here: Device partnerships can be forged. Helps optimize app performance for leading devices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-EpHcCOp1ci"
      },
      "source": [
        "#### Chart - 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "outputs": [],
      "source": [
        "# Chart - 11 visualization code\n",
        "app_data = map_user_df.groupby(\"year_quarter\")[[\"RegisteredUser\", \"AppOpens\"]].sum().reset_index()\n",
        "sns.lineplot(data=app_data, x=\"year_quarter\", y=\"RegisteredUser\", marker=\"o\", label=\"Registered Users\")\n",
        "sns.lineplot(data=app_data, x=\"year_quarter\", y=\"AppOpens\", marker=\"o\", label=\"App Opens\")\n",
        "plt.title(\"Chart 11: App Opens vs Registered Users (Map Users)\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_VqEhTip1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vsMzt_np1ck"
      },
      "source": [
        "Answer Here: Compare active engagement (App Opens) with total users (Registered Users)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zGJKyg5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      },
      "source": [
        "Answer Here: App opens often lag behind registered users, especially in newer regions — showing inactive users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "druuKYZpp1ck"
      },
      "source": [
        "Answer Here: Helps identify retention gaps. Push notifications, new features, or UX improvements can increase daily usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3dbpmDWp1ck"
      },
      "source": [
        "#### Chart - 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "outputs": [],
      "source": [
        "# Chart - 12 visualization code\n",
        "top_pin_insurance = top_ins_df.groupby(\"Pincodes\")[\"Transaction_count\"].sum().sort_values(ascending=False).head(10).reset_index()\n",
        "sns.barplot(data=top_pin_insurance, x=\"Transaction_count\", y=\"Pincodes\", palette=\"rocket\")\n",
        "plt.title(\"Chart 12: Top Pincodes by Insurance Count (Top Insurance)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylSl6qgtp1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2xqNkiQp1ck"
      },
      "source": [
        "Answer Here: Identifies high-performing areas for insurance services at a micro level."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWILFDl5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-lUsV2mp1ck"
      },
      "source": [
        "Answer Here: Urban pincodes dominate again, showing demand for risk coverage in dense populations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7G43BXep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwDJXsLp1cl"
      },
      "source": [
        "Answer Here: Helps with agent deployment, digital ad targeting, and expansion of financial literacy programs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag9LCva-p1cl"
      },
      "source": [
        "#### Chart - 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "outputs": [],
      "source": [
        "# Chart - 13 visualization code\n",
        "top_pin_users = top_user_df.groupby(\"Pincodes\")[\"RegisteredUser\"].sum().sort_values(ascending=False).head(10).reset_index()\n",
        "sns.barplot(data=top_pin_users, x=\"RegisteredUser\", y=\"Pincodes\", palette=\"crest\")\n",
        "plt.title(\"Chart 13: Top Pincodes by Registered Users (Top Users)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6MkPsBcp1cl"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V22bRsFWp1cl"
      },
      "source": [
        "Answer Here: Same as chart 9, but focuses on total users instead of transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cELzS2fp1cl"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      },
      "source": [
        "Answer Here: Many users in certain pincodes might not be high spenders. Indicates potential for upselling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MPXvC8up1cl"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL8l1tdLp1cl"
      },
      "source": [
        "Answer Here: User-heavy areas with low transactions can be targeted for onboarding drives, merchant tie-ups, or service bundling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0"
      },
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "outputs": [],
      "source": [
        "# Correlation Heatmap visualization code\n",
        "corr_data = agg_trans_df[[\"Transaction_count\", \"Transaction_amount\"]].copy()\n",
        "sns.heatmap(corr_data.corr(), annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Chart 14: Correlation Heatmap (Aggregated Transactions)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      },
      "source": [
        "Answer Here: A correlation heatmap shows the relationship between variables. Here, it tells us whether higher transaction counts correlate with higher transaction amounts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcqpst1Vc9ur"
      },
      "source": [
        "Found that : <br>\n",
        "Transaction_count & Transaction_amount\t0.67\tModerately Strong Positive Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSqtnDqZNRR"
      },
      "source": [
        "Answer Here: High correlation suggests consistent behavior — users who do more transactions also spend more. Low or no correlation may imply high-frequency but low-value usage (e.g., recharges)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q29F0dvdveiT"
      },
      "source": [
        "#### Chart - 15 - Pair Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "outputs": [],
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(agg_trans_df[[\"Transaction_count\", \"Transaction_amount\"]])\n",
        "plt.suptitle(\"Chart 15: Pair Plot of Transaction Metrics (Aggregated Transactions)\", y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXh0U9oCveiU"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMmPjTByveiU"
      },
      "source": [
        "Answer Here: A pair plot visualizes distributions and relationships between multiple metrics. Great for detecting clusters, trends, and outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22aHeOlLveiV"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPQ8RGwHveiV"
      },
      "source": [
        "Answer Here: Reveals whether there’s a linear, non-linear, or no relationship between transaction amount and count. Also helps detect anomalies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw"
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7MS06SUHkB-"
      },
      "source": [
        "Answer Here: Based on insights derived from visualizations in Charts 1–15, we defined and tested three hypothetical statements. The goal was to statistically validate trends we observed in user behavior, transaction patterns, and service usage on the PhonePe platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Hypothetical Statement - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "Answer Here:<br>\n",
        "Null Hypothesis: There is no significant difference in the average transaction amount between top 5 and bottom 5 states.\n",
        "<br>\n",
        "Alternate Hypothesis: There is a significant difference in the average transaction amount between top 5 and bottom 5 states."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Stp 1: Get total transaction count by state\n",
        "state_txn = agg_trans_df.groupby(\"States\")[[\"Transaction_count\", \"Transaction_amount\"]].sum().reset_index()\n",
        "\n",
        "# Stp 2: Identify top 5 and bottom 5 states by transaction count\n",
        "top_states = state_txn.sort_values(\"Transaction_count\", ascending=False).head(5)\n",
        "bottom_states = state_txn.sort_values(\"Transaction_count\", ascending=True).head(5)\n",
        "\n",
        "# Stp 3: Extract average transaction amounts\n",
        "top_avg = top_states[\"Transaction_amount\"]\n",
        "bottom_avg = bottom_states[\"Transaction_amount\"]\n",
        "\n",
        "# Stp 4: Perform independent t-test\n",
        "from scipy.stats import ttest_ind\n",
        "t_stat, p_value = ttest_ind(top_avg, bottom_avg)\n",
        "\n",
        "print(\"P-Value:\", p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "Answer Here: Two-Sample Independent T-Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "Answer Here.: Because we are comparing mean values of two independent groups (top vs bottom states). T-test is ideal when comparing numerical data between two groups.\n",
        "<br>\n",
        "If p < 0.05: Reject (null) → There is a significant difference.\n",
        "<br>\n",
        "If p ≥ 0.05: Fail to reject → No significant difference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Hypothetical Statement - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "Answer Here:\n",
        "Null Hypothesis: There is no correlation between App Opens and Registered Users.\n",
        "<br>\n",
        "Alternative Hypothesis: There is a positive correlation between App Opens and Registered Users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Stp 1: Group and summarize\n",
        "app_df = map_user_df.groupby(\"year_quarter\")[[\"AppOpens\", \"RegisteredUser\"]].sum().reset_index()\n",
        "\n",
        "# Stp 2: Pearson correlation test\n",
        "from scipy.stats import pearsonr\n",
        "corr_coef, p_value = pearsonr(app_df[\"AppOpens\"], app_df[\"RegisteredUser\"])\n",
        "\n",
        "print(\"Correlation Coefficient:\", corr_coef)\n",
        "print(\"P-Value:\", p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUvejAfpUZe"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "Answer Here: Pearson Correlation Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd15vwWVpUZf"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOGYyiBpUZf"
      },
      "source": [
        "Answer Here: Because it measures the linear relationship between two continuous variables (AppOpens and RegisteredUser).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_IUdTipZyH"
      },
      "source": [
        "### Hypothetical Statement - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "Answer Here: <br>\n",
        "Null- Hypothesis: Mean insurance amount is greater than or equal to the mean transaction amount.\n",
        "\n",
        "Alternative Hypothesis: Mean insurance amount is less than the mean transaction amount."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Stp 1: Get relevant data\n",
        "mean_insurance = agg_ins_df[\"Insurance_amount\"].mean()\n",
        "mean_transaction = agg_trans_df[\"Transaction_amount\"].mean()\n",
        "\n",
        "# Stp 2: Perform one-sided t-test\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# H₀: insurance >= transaction → We'll test: insurance - transaction < 0\n",
        "# Convert transaction mean to sample baseline\n",
        "t_stat, p_value = ttest_1samp(agg_ins_df[\"Insurance_amount\"], popmean=mean_transaction)\n",
        "\n",
        "print(\"P-Value:\", p_value / 2)  # one-tailed test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLW572S8pZyI"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWJ8v15pZyI"
      },
      "source": [
        "Answer Here:  One-Sample T-Test (One-Sided)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWbDXHzopZyI"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99G98V6pZyI"
      },
      "source": [
        "Answer Here: We're testing if one group's mean (insurance) is significantly lower than a known population mean (transaction)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyOF9F70UgQ"
      },
      "source": [
        "### 1. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "outputs": [],
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "#Handling missing values is done in the prev steps\n",
        "## Fill missing Pincodes with mode (most frequent) value\n",
        "#top_ins_df[\"Pincodes\"].fillna(top_ins_df[\"Pincodes\"].mode()[0], inplace=True)\n",
        "#top_trans_df[\"Pincodes\"].fillna(top_trans_df[\"Pincodes\"].mode()[0], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wuGOrhz0itI"
      },
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ixusLtI0pqI"
      },
      "source": [
        "Answer Here: used Mode imputation is effective for categorial columns like Pincodes, especially when missingness is minimal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id1riN9m0vUs"
      },
      "source": [
        "### 2. Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "outputs": [],
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Outlier detection in transaction amount\n",
        "Q1 = agg_trans_df['Transaction_amount'].quantile(0.25)\n",
        "Q3 = agg_trans_df['Transaction_amount'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower = Q1 - 1.5 * IQR\n",
        "upper = Q3 + 1.5 * IQR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578E2V7j08f6"
      },
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGZz5OrT1HH-"
      },
      "source": [
        "Answer Here:<br>\n",
        "Techniques Used:<br>\n",
        "IQR Method (Interquartile Range) for continuous columns like Transaction_amount, Insurance_amount, etc.....\n",
        "<br>\n",
        "Why Used?<br>\n",
        "IQR helps detect non-normal outliers.\n",
        "statistical method used to reduce the impact of outliers on data analysis... reduces impact of extreme values without deleting rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 3. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "outputs": [],
      "source": [
        "# Encode your categorical columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "agg_trans_df['Quarter'] = LabelEncoder().fit_transform(agg_trans_df['Quarter'])\n",
        "\n",
        "# One-hot encode Transaction Type\n",
        "agg_trans_encoded = pd.get_dummies(agg_trans_df, columns=['Transaction_type'], drop_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67NQN5KX2AMe"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaue5h32n_G"
      },
      "source": [
        "Answer Here:<br>\n",
        "Techniques Used:\n",
        "Label Encoding for ordinal-type categorical values (Quarter)--> where order matters\n",
        "\n",
        "One-Hot Encoding for nominal categories like States, Transaction_type, Brands..... non-ordinal data( data that is categorized into groups with no inherent order or ranking) for use in ML models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwf50b-R2tYG"
      },
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTmPy08KDQCU"
      },
      "source": [
        "# These datasets are numerical/categorical. There are no textual/NLP columns, so steps like.... needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMQiZwjn3iu7"
      },
      "source": [
        "#### 1. Expand Contraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "outputs": [],
      "source": [
        "# Expand Contraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVIkgGqN3qsr"
      },
      "source": [
        "#### 2. Lower Casing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "outputs": [],
      "source": [
        "# Lower Casing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkPnILGE3zoT"
      },
      "source": [
        "#### 3. Removing Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "outputs": [],
      "source": [
        "# Remove Punctuations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlsf0x5436Go"
      },
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "outputs": [],
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT9DMSJo4nBL"
      },
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "outputs": [],
      "source": [
        "# Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "outputs": [],
      "source": [
        "# Remove White spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c49ITxTc407N"
      },
      "source": [
        "#### 6. Rephrase Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "outputs": [],
      "source": [
        "# Rephrase Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeJFEK0N496M"
      },
      "source": [
        "#### 7. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "outputs": [],
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ExmJH0g5HBk"
      },
      "source": [
        "#### 8. Text Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "outputs": [],
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNqERVU536h"
      },
      "source": [
        "##### Which text normalization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9jKVxE06BC1"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5UmGsbsOxih"
      },
      "source": [
        "#### 9. Part of speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "outputs": [],
      "source": [
        "# POS Taging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      },
      "source": [
        "#### 10. Text Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "outputs": [],
      "source": [
        "# Vectorizing Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBMux9mC6MCf"
      },
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su2EnbCh6UKQ"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 4. Feature Manipulation & Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C74aWNz2AliB"
      },
      "source": [
        "#### 1. Feature Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "outputs": [],
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "#This is already created in above step near data processing....\n",
        "#agg_trans_df[\"Year_Quarter\"] = agg_trans_df[\"Years\"].astype(str) + \"-Q\" + agg_trans_df[\"Quarter\"].astype(str)\n",
        "#etc..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DejudWSA-a0"
      },
      "source": [
        "#### 2. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "outputs": [],
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# Feature Selection Methods:\n",
        "# Correlation Matrix (Chart 14) to detect multicollinearity\n",
        "\n",
        "# Domain Understanding to retain features like:\n",
        "\n",
        "# Transaction_amount, Transaction_count, RegisteredUser, AppOpens States, Brands, Pincodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEMng2IbBLp7"
      },
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      },
      "source": [
        "Answer Here: <br>\n",
        " Feature Selection Methods:\n",
        "Correlation Matrix (Chart 14) to detect multicollinearity\n",
        "<br>\n",
        "Domain Understanding to retain features like:<br>\n",
        "Transaction_amount, Transaction_count\n",
        "RegisteredUser, AppOpens\n",
        "States, Brands, Pincodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      },
      "source": [
        "##### Which all features you found important and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgaEstsBnaf"
      },
      "source": [
        "Answer Here: <br>\n",
        "Transaction_amount, Transaction_count: Direct indicators of usage.\n",
        "\n",
        "\n",
        "RegisteredUser, AppOpens: Reflect user engagement.\n",
        "\n",
        "\n",
        "States, Brands: Useful for demographic and usage pattern segmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 5. Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqoHp30x9hH9"
      },
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkCbwRzdEV3d"
      },
      "source": [
        "#### Yes — the data is right-skewed (transactions/amounts), so log transformation helps normalize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "outputs": [],
      "source": [
        "# Transform Your data\n",
        "agg_trans_df[\"log_transaction_amount\"] = np.log1p(agg_trans_df[\"Transaction_amount\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shm6iIN6EvGr"
      },
      "source": [
        "Answer: Stabilizes variance......And,\n",
        "Improves model performance (especially linear models)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDnDkt2B6du"
      },
      "source": [
        "### 6. Data Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "outputs": [],
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_values = scaler.fit_transform(agg_trans_df[[\"Transaction_count\", \"Transaction_amount\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiVWRdJDDil"
      },
      "source": [
        "##### Which method have you used to scale you data and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wldik0HZEfk9"
      },
      "source": [
        "Answer: MinMaxScaler for normalization (0 to 1)<br>\n",
        "Ensures features are on same scale.\n",
        "\n",
        "Prevents dominance by high-valued features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UUpS68QDMuG"
      },
      "source": [
        "### 7. Dimesionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexQrXU-DjzY"
      },
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      },
      "source": [
        "Answer Here: <br>\n",
        "Not strongly needed here as we have fewer features and have already done:\n",
        "Feature selection\n",
        "Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "outputs": [],
      "source": [
        "# DImensionality Reduction (If needed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5CmagL3EC8N"
      },
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKr75IDuEM7t"
      },
      "source": [
        "Answer Here: If needed: PCA could be used when scaling + encoding produce high-dimensional data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 8. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "outputs": [],
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = agg_trans_df[[\"Transaction_count\", \"Transaction_amount\"]]\n",
        "y = agg_trans_df[\"Years\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKvONjwE8ra"
      },
      "source": [
        "##### What data splitting ratio have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      },
      "source": [
        "Answer Here: 80:20 used for training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1XJ9OREExlT"
      },
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOzZv6IFROw"
      },
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeKDIv7pFgcC"
      },
      "source": [
        "Answer Here: No, this is not a classification dataset with imbalance problems like fraud detection. The targets are not binary labels — they're numeric values (amount, counts, etc.....)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "outputs": [],
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIqpNgepFxVj"
      },
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbet1HwdGDTz"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation\n",
        "#Importing required libraries\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Load Dataset\n",
        "df = pd.read_csv(\"/content/sample_data/aggregated_transaction.csv\")\n",
        "\n",
        "#clean and prepare data\n",
        "df = df.drop(columns=[\"States\", \"Transaction_type\"])\n",
        "df = df.dropna()\n",
        "# Split into features and target\n",
        "X = df.drop(\"Transaction_amount\", axis=1)\n",
        "y = df[\"Transaction_amount\"]\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the Algorithm\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"MSE: \", mse)\n",
        "print(\"R2: \", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJBuiUVfxKd"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics_df = pd.DataFrame({\"Model\": [\"Linear Regression\"], \"MSE\": [mse], \"R2 Score\": [r2]})\n",
        "sns.barplot(x=\"Model\", y=\"R2 Score\", data=metrics_df)\n",
        "plt.title(\"Model Evaluation (R² Score)\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qY1EAkEfxKe"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Cross-validation\n",
        "# cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
        "# print(\"Cross-Validation R2 Scores:\", cv_scores)\n",
        "# print(\"Mean CV R2 Score:\", cv_scores.mean())\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "negyGRa7fxKf"
      },
      "source": [
        "Answer Here: Used Cross-Validation (5-fold) with GridSearchCV where applicable (for models like Random Forest, SVM)...\n",
        "<br>\n",
        "Soo, For Linear Regression, no hyperparameters are tunable, but CV helps evaluate model robustness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfvqoZmBfxKf"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaLui8CcfxKf"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYfwnehpsJ1"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Load data\n",
        "df = pd.read_csv(\"/content/sample_data/aggregated_transaction.csv\")\n",
        "df = df.drop(columns=[\"States\", \"Transaction_type\"])\n",
        "df = df.dropna()\n",
        "\n",
        "X = df.drop(\"Transaction_amount\", axis=1)\n",
        "y = df[\"Transaction_amount\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "print(\"MSE:\", mse_rf)\n",
        "print(\"R2 Score:\", r2_rf)\n",
        "\n",
        "\n",
        "# Visualizing evaluation Metric Score chart\n",
        "metrics_rf = pd.DataFrame({\"Model\": [\"Random Forest\"], \"MSE\": [mse_rf], \"R2 Score\": [r2_rf]})\n",
        "sns.barplot(x=\"Model\", y=\"R2 Score\", data=metrics_rf)\n",
        "plt.title(\"Model Evaluation (R² Score)\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# GridSearch for RF\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "# Fit the Algorithm\n",
        "grid_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3, scoring='r2')\n",
        "grid_rf.fit(X_train, y_train)\n",
        "best_rf = grid_rf.best_estimator_\n",
        "y_pred_rf_best = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "r2_rf_best = r2_score(y_test, y_pred_rf_best)\n",
        "mse_rf_best = mean_squared_error(y_test, y_pred_rf_best)\n",
        "print(\"Best Params:\", grid_rf.best_params_)\n",
        "print(\"Improved R2:\", r2_rf_best)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAih1iBOpsJ2"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      },
      "source": [
        "Answer Here: <br>\n",
        "GridSearchCV was chosen because:\n",
        "\n",
        "Easy to implement.\n",
        "\n",
        "Works well on smaller hyperparameter space.\n",
        "\n",
        "Ensures best combination is chosen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74yRdG6UpsJ3"
      },
      "source": [
        "Answer Here:\n",
        "Improved R² Score and reduced MSE.\n",
        "\n",
        "Random Forest with tuned parameters is more robust and accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fze-IPXLpx6K"
      },
      "source": [
        "### ML Model - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation\n",
        "from xgboost import XGBRegressor\n",
        "# Fit the Algorithm\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "#Evaluation\n",
        "# Evaluation\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "print(\"MSE:\", mse_xgb)\n",
        "print(\"R2 Score:\", r2_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AN1z2sKpx6M"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics_xgb = pd.DataFrame({\"Model\": [\"XGBoost\"], \"MSE\": [mse_xgb], \"R2 Score\": [r2_xgb]})\n",
        "sns.barplot(x=\"Model\", y=\"R2 Score\", data=metrics_xgb)\n",
        "plt.title(\"Model Evaluation (R² Score)\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PIHJqyupx6M"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "xgb_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "# Fit the Algorithm\n",
        "grid_xgb = GridSearchCV(XGBRegressor(objective='reg:squarederror', random_state=42),\n",
        "                        xgb_params, cv=3, scoring='r2')\n",
        "grid_xgb.fit(X_train, y_train)\n",
        "best_xgb = grid_xgb.best_estimator_\n",
        "y_pred_xgb_best = best_xgb.predict(X_test)\n",
        "# Predict on the model\n",
        "r2_xgb_best = r2_score(y_test, y_pred_xgb_best)\n",
        "mse_xgb_best = mean_squared_error(y_test, y_pred_xgb_best)\n",
        "print(\"Best Params:\", grid_xgb.best_params_)\n",
        "print(\"Improved R2:\", r2_xgb_best)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-qAgymDpx6N"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQMffxkwpx6N"
      },
      "source": [
        "Answer Here: Grid Search CV because\n",
        "\n",
        "> Add blockquote\n",
        "\n",
        "\n",
        "> Easy to implement.\n",
        "\n",
        "> Works well on smaller hyperparameter space.\n",
        "\n",
        "Ensures best combination is chosen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hykwinpx6N"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzVzZC6opx6N"
      },
      "source": [
        "Answer Here: R² Score improves after tuning max_depth, learning_rate, and n_estimators.\n",
        "\n",
        "Lower MSE compared to both Linear Regression and Random Forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CCil-SKHpo"
      },
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVz9hHDKFms"
      },
      "source": [
        "Answer Here: <br>\n",
        "Metrics Chosen:\n",
        "R² Score (Coefficient of Determination)\n",
        "\n",
        "MSE (Mean Squared Error)\n",
        "\n",
        "Cross-Validation Score (CV R²)\n",
        "\n",
        "\n",
        "-----------------------------------------\n",
        "| Metric                     | Reason for Business Impact                                                                                                      |\n",
        "| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **R² Score**               | Indicates how well the model captures transaction behavior. <br> <br>High R² → better decision-making, forecasting, and budgeting.       |\n",
        "| **MSE**                    | Measures prediction accuracy.<br> <br> Lower MSE → fewer costly prediction errors, especially in financial projections.                  |\n",
        "| **Cross-Validation Score** | Ensures model reliability across different time periods/states. <br> <br>This improves scalability for business planning in new regions. |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFFvTBNJzUa"
      },
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      },
      "source": [
        "Answer Here: Final Model Chosen:  XGBoost Regressor\n",
        "Why:\n",
        "- Highest R² Score\t~0.92 — Best model fit\n",
        "- Lowest MSE\tMore accurate predictions than others\n",
        "- Handles Non-linearity\tLearns complex patterns in transaction data\n",
        "- Feature Importance\tBuilt-in support to analyze business-driving factors\n",
        "- Efficiency\tScalable and fast, suitable for large PhonePe datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGl1hHyA_VK"
      },
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvVTiIxBL-C"
      },
      "source": [
        "Answer Here: Model Explanation: XGBoost Regressor<br>\n",
        "\n",
        "Type: Ensemble Gradient Boosting Model\n",
        "\n",
        "Importance:\n",
        "- Handles missing data\n",
        "\n",
        "- Combines many weak learners into a strong one\n",
        "\n",
        "- Regularization to avoid overfitting\n",
        "\n",
        "- Very accurate for tabular datasets (like PhonePe's)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyNgTHvd2WFk"
      },
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5McJBi2d8v"
      },
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "outputs": [],
      "source": [
        "# Save the File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      },
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "outputs": [],
      "source": [
        "# Load the File and predict unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kee-DAl2viO"
      },
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TalBUwtgieU9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Load and clean data\n",
        "df = pd.read_csv(\"/content/sample_data/aggregated_transaction.csv\")\n",
        "df = df.drop(columns=[\"States\", \"Transaction_type\"])\n",
        "df = df.dropna()\n",
        "\n",
        "X = df.drop(\"Transaction_amount\", axis=1)\n",
        "y = df[\"Transaction_amount\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. Linear Regression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_pred = lr.predict(X_test)\n",
        "lr_r2 = r2_score(y_test, lr_pred)\n",
        "lr_mse = mean_squared_error(y_test, lr_pred)\n",
        "\n",
        "# 2. Random Forest\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "rf_r2 = r2_score(y_test, rf_pred)\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "\n",
        "# 3. XGBoost\n",
        "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "xgb_pred = xgb.predict(X_test)\n",
        "xgb_r2 = r2_score(y_test, xgb_pred)\n",
        "xgb_mse = mean_squared_error(y_test, xgb_pred)\n",
        "\n",
        "# Combine into DataFrame\n",
        "metrics_df = pd.DataFrame({\n",
        "    \"Model\": [\"Linear Regression\", \"Random Forest\", \"XGBoost\"],\n",
        "    \"R2 Score\": [lr_r2, rf_r2, xgb_r2],\n",
        "    \"MSE\": [lr_mse, rf_mse, xgb_mse]\n",
        "})\n",
        "\n",
        "# Plot R² Score Comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=\"Model\", y=\"R2 Score\", data=metrics_df, palette=\"viridis\")\n",
        "plt.title(\"Model Comparison: R² Score\")\n",
        "plt.ylim(0, 1)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot MSE Comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=\"Model\", y=\"MSE\", data=metrics_df, palette=\"rocket\")\n",
        "plt.title(\"Model Comparison: Mean Squared Error\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# metrics table\n",
        "print(metrics_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi5EeuzZ_7Eq"
      },
      "source": [
        "# After Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fj0HHHZVixoh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load and prepare the data\n",
        "df = pd.read_csv(\"/content/sample_data/aggregated_transaction.csv\")\n",
        "df = df.drop(columns=[\"States\", \"Transaction_type\"])\n",
        "df = df.dropna()\n",
        "\n",
        "X = df.drop(\"Transaction_amount\", axis=1)\n",
        "y = df[\"Transaction_amount\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. Linear Regression (with cross-validation)\n",
        "lr = LinearRegression()\n",
        "cv_r2 = cross_val_score(lr, X_train, y_train, cv=5, scoring='r2').mean()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_pred = lr.predict(X_test)\n",
        "lr_r2 = r2_score(y_test, lr_pred)\n",
        "lr_mse = mean_squared_error(y_test, lr_pred)\n",
        "\n",
        "# 2. Random Forest with GridSearchCV\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "rf_grid = GridSearchCV(RandomForestRegressor(random_state=42), rf_param_grid, cv=3, scoring='r2')\n",
        "rf_grid.fit(X_train, y_train)\n",
        "best_rf = rf_grid.best_estimator_\n",
        "rf_pred = best_rf.predict(X_test)\n",
        "rf_r2 = r2_score(y_test, rf_pred)\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "\n",
        "# 3. XGBoost with GridSearchCV\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5],\n",
        "    'learning_rate': [0.05, 0.1]\n",
        "}\n",
        "xgb_grid = GridSearchCV(XGBRegressor(objective='reg:squarederror', random_state=42),\n",
        "                        xgb_param_grid, cv=3, scoring='r2')\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "best_xgb = xgb_grid.best_estimator_\n",
        "xgb_pred = best_xgb.predict(X_test)\n",
        "xgb_r2 = r2_score(y_test, xgb_pred)\n",
        "xgb_mse = mean_squared_error(y_test, xgb_pred)\n",
        "\n",
        "# Compile results\n",
        "final_metrics_df = pd.DataFrame({\n",
        "    \"Model\": [\"Linear Regression\", \"Random Forest (Tuned)\", \"XGBoost (Tuned)\"],\n",
        "    \"R2 Score\": [lr_r2, rf_r2, xgb_r2],\n",
        "    \"MSE\": [lr_mse, rf_mse, xgb_mse]\n",
        "})\n",
        "\n",
        "# Plot R2 Score\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=\"Model\", y=\"R2 Score\", data=final_metrics_df, palette=\"crest\")\n",
        "plt.title(\"Tuned Model Comparison: R² Score\")\n",
        "plt.ylim(0, 1)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot MSE\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=\"Model\", y=\"MSE\", data=final_metrics_df, palette=\"flare\")\n",
        "plt.title(\"Tuned Model Comparison: Mean Squared Error\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final table\n",
        "print(\"\\n🔎 Final Tuned Model Performance:\")\n",
        "print(final_metrics_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "Write the conclusion here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRe8meRhSh_p"
      },
      "source": [
        "This project effectively demonstrates the practical applications of data analytics in the fintech domain. From extracting and cleaning data to deriving meaningful insights and presenting them in a user-friendly dashboard, every step showcases the power of data-driven decision-making. The PhonePe Transaction Insights project not only improves understanding of transaction behavior across Indian geographies but also offers valuable metrics for business strategies like customer segmentation, marketing optimization, and product development.\n",
        "\n",
        "Moreover, it equips aspiring data professionals with crucial technical skills including SQL proficiency, Python analytics, data visualization, Streamlit dashboard development, and business insight generation. This project is a testament to the power of open data and the value it can offer when analyzed with the right tools and approach.\n",
        "> Thank You"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIfDvo9L0UH2"
      },
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning  !!!***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "g-ATYxFrGrvw",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "C74aWNz2AliB",
        "TfvqoZmBfxKf",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}